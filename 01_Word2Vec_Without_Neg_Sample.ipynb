{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "558yxD7wtnyH"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTY1eMkL1hGi",
        "outputId": "6b536102-93ca-4889-8169-80d4cb6cdc76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x785ea9b1a130>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import reuters, stopwords\n",
        "\n",
        "nltk.download('reuters')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# to ensure to produce same random number to debug and model comparison\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScH3i6CC4-KY"
      },
      "source": [
        "**Prepare the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4oDuaa0wrEW",
        "outputId": "fb2a347c-dd08-4b52-b3bf-b4514aca36fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 10788\n"
          ]
        }
      ],
      "source": [
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "sentences = []\n",
        "\n",
        "for fileid in reuters.fileids():\n",
        "    words = [\n",
        "        w.lower()\n",
        "        for w in reuters.words(fileid)\n",
        "        # clean the dataset document by removing stopwords\n",
        "        if w.isalpha() and w.lower() not in stop_words\n",
        "    ]\n",
        "    sentences.append(words)\n",
        "\n",
        "print(\"Total sentences:\", len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hWgkY8ixwmw",
        "outputId": "db5f4d3e-4dcb-4fe3-9a3b-5204f98e72b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 10000\n",
            "UNK index: 0\n"
          ]
        }
      ],
      "source": [
        "# set vocab limit to avoid training the model fneeds GPU for londer period\n",
        "VOCAB_LIMIT = 10000\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "all_words = [w for sentence in sentences for w in sentence]\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# build the vocabulary\n",
        "vocab = [UNK_TOKEN] + [\n",
        "    word for word, _ in word_counts.most_common(VOCAB_LIMIT - 1)\n",
        "]\n",
        "\n",
        "word2index = {word: idx for idx, word in enumerate(vocab)}\n",
        "index2word = {idx: word for word, idx in word2index.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"UNK index:\", word2index[UNK_TOKEN])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDBRRTb1x24O"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for sentence in sentences:\n",
        "    indexed_sentence = [\n",
        "        # each word is replaced by its index from word2index\n",
        "        # this is to make dataset ready for model training\n",
        "        word2index.get(word, word2index[UNK_TOKEN])\n",
        "        for word in sentence\n",
        "    ]\n",
        "    corpus.append(indexed_sentence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCi4_dp9u4GC"
      },
      "source": [
        "**Prepare Train Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb4genh51taM"
      },
      "outputs": [],
      "source": [
        "# dynamic windows where default is 2\n",
        "def random_batch(batch_size, corpus, window_size=2):\n",
        "    input_batch = []\n",
        "    label_batch = []\n",
        "\n",
        "    while len(input_batch) < batch_size:\n",
        "\n",
        "        # pick a random sentence index\n",
        "        sentence_idx = random.randint(0, len(corpus) - 1)\n",
        "        sentence = corpus[sentence_idx]\n",
        "\n",
        "        # ensure sentence is long enough to pick a center and context word\n",
        "        if len(sentence) < 2 * window_size + 1:\n",
        "            continue\n",
        "\n",
        "        # pick a random center word position within the sentence\n",
        "        center_word_pos = random.randint(window_size, len(sentence) - 1 - window_size)\n",
        "        center_word_index = sentence[center_word_pos]\n",
        "\n",
        "        # pick a random context word position within the window around the center word\n",
        "        # and ensure it's not the center word itself\n",
        "        context_word_pos = random.choice(\n",
        "            list(range(center_word_pos - window_size, center_word_pos + window_size + 1))\n",
        "        )\n",
        "        if context_word_pos == center_word_pos:\n",
        "            continue\n",
        "        context_word_index = sentence[context_word_pos]\n",
        "\n",
        "        input_batch.append(center_word_index)\n",
        "        label_batch.append(context_word_index)\n",
        "\n",
        "    return input_batch, label_batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgfj7fnvvQJl"
      },
      "source": [
        "**Implement the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W1Gvm741wUn"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Skipgram(nn.Module):\n",
        "\n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
        "\n",
        "    def forward(self, center, outside, all_vocabs):\n",
        "        center_embedding  = self.embedding_center(center).unsqueeze(1)\n",
        "        outside_embedding = self.embedding_outside(outside).unsqueeze(1)\n",
        "        all_embedding     = self.embedding_outside(all_vocabs)\n",
        "\n",
        "        top_term = torch.exp(\n",
        "            outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
        "        )\n",
        "\n",
        "        lower_term = all_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), dim=1)\n",
        "\n",
        "        loss = -torch.mean(torch.log(top_term / lower_term_sum))\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX0Yd6QyvVs8"
      },
      "source": [
        "**Set Hyperparameters for Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhdy9mpT1zNu"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "batch_size = 128\n",
        "num_epochs = 5000\n",
        "learning_rate = 0.001\n",
        "window_size = 2\n",
        "\n",
        "model = Skipgram(vocab_size, embedding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "all_vocabs = torch.LongTensor(range(vocab_size))\n",
        "all_vocabs = all_vocabs.unsqueeze(0).repeat(batch_size, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4XnI5CIvrPs"
      },
      "source": [
        "**Test the model before training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt65KFWE11qJ",
        "outputId": "7571b7b8-6a5d-40f4-dd3f-50bc1737d2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial test loss (before training): 38.501251220703125\n"
          ]
        }
      ],
      "source": [
        "# get a batch\n",
        "x_batch, y_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "# create tensors first\n",
        "input_tensor = torch.LongTensor(x_batch)\n",
        "label_tensor = torch.LongTensor(y_batch)\n",
        "\n",
        "# create all_vocabs\n",
        "all_vocabs = torch.LongTensor(range(vocab_size))\n",
        "all_vocabs = all_vocabs.unsqueeze(0).repeat(input_tensor.size(0), 1)\n",
        "\n",
        "# test loss\n",
        "test_loss = model(input_tensor, label_tensor, all_vocabs)\n",
        "print(\"Initial test loss (before training):\", test_loss.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpib0lomvzoh"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMeY0mvHsTMX",
        "outputId": "4bbf3860-815f-4196-b635-96b32cfb574a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 500 | Loss: 23.140018\n",
            "Epoch 1000 | Loss: 22.115686\n",
            "Epoch 1500 | Loss: 20.569551\n",
            "Epoch 2000 | Loss: 19.657822\n",
            "Epoch 2500 | Loss: 17.945671\n",
            "Epoch 3000 | Loss: 15.884174\n",
            "Epoch 3500 | Loss: 14.302668\n",
            "Epoch 4000 | Loss: 14.190167\n",
            "Epoch 4500 | Loss: 14.916005\n",
            "Epoch 5000 | Loss: 13.188715\n",
            "\n",
            "Training completed in 4456.45 seconds\n",
            "Final training loss: 13.188715\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# list to store losses\n",
        "losses = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    x_batch, y_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    # tensors first\n",
        "    input_tensor = torch.LongTensor(x_batch)\n",
        "    label_tensor = torch.LongTensor(y_batch)\n",
        "\n",
        "    # then all_vocabs\n",
        "    all_vocabs = torch.LongTensor(range(vocab_size))\n",
        "    all_vocabs = all_vocabs.unsqueeze(0).repeat(input_tensor.size(0), 1)\n",
        "\n",
        "    # forward pass\n",
        "    loss = model(input_tensor, label_tensor, all_vocabs)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # store the loss\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(f\"Epoch {epoch+1} | Loss: {loss.item():.6f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTraining completed in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Print final loss\n",
        "print(f\"Final training loss: {losses[-1]:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk251VAh0DWQ"
      },
      "source": [
        "**Save the Trained Word2Vec model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtJ7C0LY0HKs",
        "outputId": "6d51a75e-c70e-4319-a463-98ce5b1771b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to word2vec_skipgram.pth\n"
          ]
        }
      ],
      "source": [
        "MODEL_PATH = \"word2vec_skipgram.pth\"\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"word2index\": word2index,\n",
        "    \"index2word\": index2word,\n",
        "    \"embedding_dim\": embedding_dim\n",
        "}, MODEL_PATH)\n",
        "\n",
        "print(\"Model saved to\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dvxrpmb0awt"
      },
      "source": [
        "**Load the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx3yY_pc0hvg",
        "outputId": "cc1e619b-6bda-4825-aa46-5be4d6c17b08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Skipgram(\n",
              "  (embedding_center): Embedding(10000, 100)\n",
              "  (embedding_outside): Embedding(10000, 100)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load(\"word2vec_skipgram.pth\", map_location=\"cpu\")\n",
        "\n",
        "word2index = checkpoint[\"word2index\"]\n",
        "index2word = checkpoint[\"index2word\"]\n",
        "embedding_dim = checkpoint[\"embedding_dim\"]\n",
        "\n",
        "vocab_size = len(word2index)\n",
        "\n",
        "model = Skipgram(vocab_size, embedding_dim)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LC5l7PK0tfQ"
      },
      "source": [
        "**Extract embeddings from the loaded model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myAUuzH_0xrM"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "embeddings = model.embedding_center.weight.data\n",
        "embeddings = F.normalize(embeddings, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbMPpexg03vm"
      },
      "source": [
        "**Evaluate semantic & syntactic accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDAqQCMo6pTO"
      },
      "outputs": [],
      "source": [
        "# load word analogies dataset and returns two lists for semantic and synthetic evaluation\n",
        "def load_analogy_dataset(filepath):\n",
        "    semantic = []\n",
        "    syntactic = []\n",
        "\n",
        "    current_section = None\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line.startswith(\":\"):\n",
        "                if \"capital-common-countries\" in line:\n",
        "                    current_section = \"semantic\"\n",
        "                elif \"past-tense\" in line:\n",
        "                    current_section = \"syntactic\"\n",
        "                else:\n",
        "                    current_section = None\n",
        "                continue\n",
        "\n",
        "            if current_section is None:\n",
        "                continue\n",
        "\n",
        "            words = line.lower().split()\n",
        "            if len(words) != 4:\n",
        "                continue\n",
        "\n",
        "            if current_section == \"semantic\":\n",
        "                semantic.append(words)\n",
        "            else:\n",
        "                syntactic.append(words)\n",
        "\n",
        "    return semantic, syntactic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIVcunJF7AHF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def analogy_accuracy(analogies, embeddings, word2index, index2word):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    vocab_size = embeddings.size(0)\n",
        "\n",
        "    for a, b, c, d in analogies:\n",
        "        if a not in word2index or b not in word2index \\\n",
        "           or c not in word2index or d not in word2index:\n",
        "            continue\n",
        "\n",
        "        va = embeddings[word2index[a]]\n",
        "        vb = embeddings[word2index[b]]\n",
        "        vc = embeddings[word2index[c]]\n",
        "\n",
        "        # word2Vec analogy: b - a + c\n",
        "        target_vec = vb - va + vc\n",
        "        target_vec = F.normalize(target_vec.unsqueeze(0), dim=1)\n",
        "\n",
        "        # cosine similarity with all words\n",
        "        similarities = torch.matmul(target_vec, embeddings.T).squeeze()\n",
        "\n",
        "        # exclude query words\n",
        "        similarities[word2index[a]] = -1e9\n",
        "        similarities[word2index[b]] = -1e9\n",
        "        similarities[word2index[c]] = -1e9\n",
        "\n",
        "        predicted_index = torch.argmax(similarities).item()\n",
        "        predicted_word = index2word[predicted_index]\n",
        "\n",
        "        if predicted_word == d:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return correct / total if total > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac1F1o21023C"
      },
      "outputs": [],
      "source": [
        "\n",
        "semantic, syntactic = load_analogy_dataset(\"/content/word_analogies_dataset.txt\")\n",
        "\n",
        "semantic_acc = analogy_accuracy(\n",
        "    semantic, embeddings, word2index, index2word\n",
        ")\n",
        "\n",
        "syntactic_acc = analogy_accuracy(\n",
        "    syntactic, embeddings, word2index, index2word\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pPqqCf71DpJ",
        "outputId": "8f16f190-b194-421c-b156-e28199182181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic accuracy: 0.0000\n",
            "Syntactic accuracy: 0.0000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Semantic accuracy: {semantic_acc:.4f}\")\n",
        "print(f\"Syntactic accuracy: {syntactic_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ivZzwZtjkbP"
      },
      "source": [
        "**Load similarity dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UYf9mLr7jmwo",
        "outputId": "0f9ca28e-540b-4976-9fbd-25e4545a1bc8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sim_df\",\n  \"rows\": 353,\n  \"fields\": [\n    {\n      \"column\": \"Word 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 206,\n        \"samples\": [\n          \"benchmark\",\n          \"atmosphere\",\n          \"weapon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"animal\",\n          \"quarrel\",\n          \"payment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Human (Mean)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0329921866962284,\n        \"min\": 0.3125,\n        \"max\": 10.0,\n        \"num_unique_values\": 146,\n        \"samples\": [\n          2.75,\n          3.1875,\n          4.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sim_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7dd076f3-2d9a-423f-8266-bb21184689cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Human (Mean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admission</td>\n",
              "      <td>ticket</td>\n",
              "      <td>5.5360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>chemistry</td>\n",
              "      <td>4.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>metal</td>\n",
              "      <td>6.6250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>announcement</td>\n",
              "      <td>effort</td>\n",
              "      <td>2.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>announcement</td>\n",
              "      <td>news</td>\n",
              "      <td>7.1875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dd076f3-2d9a-423f-8266-bb21184689cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7dd076f3-2d9a-423f-8266-bb21184689cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7dd076f3-2d9a-423f-8266-bb21184689cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Word 1     Word 2  Human (Mean)\n",
              "0     admission     ticket        5.5360\n",
              "1       alcohol  chemistry        4.1250\n",
              "2      aluminum      metal        6.6250\n",
              "3  announcement     effort        2.0625\n",
              "4  announcement       news        7.1875"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load similarity dataset\n",
        "sim_df = pd.read_csv(\"/content/wordsim353crowd.csv\")\n",
        "\n",
        "sim_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4GJ1OFaj3m4"
      },
      "source": [
        "**Compute dot-product similarities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WUKe7ICj6Ja",
        "outputId": "42b089f7-1679-4118-d7fa-cf76a7364405"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-573930044.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  w1 = str(row[0]).lower()\n",
            "/tmp/ipython-input-573930044.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  w2 = str(row[1]).lower()\n",
            "/tmp/ipython-input-573930044.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  human_score = float(row[2])\n"
          ]
        }
      ],
      "source": [
        "model_sims = []\n",
        "human_sims = []\n",
        "\n",
        "UNK_INDEX = word2index.get(\"<UNK>\")\n",
        "\n",
        "for _, row in sim_df.iterrows():\n",
        "    w1 = str(row[0]).lower()\n",
        "    w2 = str(row[1]).lower()\n",
        "    human_score = float(row[2])\n",
        "\n",
        "    idx1 = word2index.get(w1, UNK_INDEX)\n",
        "    idx2 = word2index.get(w2, UNK_INDEX)\n",
        "\n",
        "    v1 = embeddings[idx1]\n",
        "    v2 = embeddings[idx2]\n",
        "\n",
        "    dot_sim = torch.dot(v1, v2).item()\n",
        "\n",
        "    model_sims.append(dot_sim)\n",
        "    human_sims.append(human_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX_rb1-8kCoa"
      },
      "source": [
        "**Calculate Spearman correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j81WQF75kHHY",
        "outputId": "ac3d04c6-9d98-4f33-fde5-07c4bdb0b01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman Correlation: 0.1131\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "correlation, p_value = spearmanr(model_sims, human_sims)\n",
        "\n",
        "print(f\"Spearman Correlation: {correlation:.4f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
