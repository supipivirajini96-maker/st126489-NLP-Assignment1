{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ofeep8kzP6B"
      },
      "source": [
        "# GloVE\n",
        "\n",
        "Let's work on implementation of GloVE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qo2GlVlzP6D",
        "outputId": "52d806e3-988e-4b8b-f765-aaa429a56c28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a21947e9ff0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import reuters, stopwords\n",
        "\n",
        "nltk.download('reuters')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# to ensure to produce same random number to debug and model comparison\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8AoV2DfzP6E"
      },
      "source": [
        "## 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIpWt2S_zc3j",
        "outputId": "5d73b017-02c5-4d5e-8d20-f1f8b2d7383c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 10788\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "sentences = []\n",
        "\n",
        "for fileid in reuters.fileids():\n",
        "    words = [\n",
        "        w.lower()\n",
        "        for w in reuters.words(fileid)\n",
        "        # clean the dataset document by removing stopwords\n",
        "        if w.isalpha() and w.lower() not in stop_words\n",
        "    ]\n",
        "    sentences.append(words)\n",
        "\n",
        "print(\"Total sentences:\", len(sentences))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viQSazpVzf9F",
        "outputId": "ea5adda6-afe8-406b-99e0-c1b5016ed268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 10000\n",
            "UNK index: 0\n"
          ]
        }
      ],
      "source": [
        "# set vocab limit to avoid training the model fneeds GPU for londer period\n",
        "VOCAB_LIMIT = 10000\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "all_words = [w for sentence in sentences for w in sentence]\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# build the vocabulary\n",
        "vocab = [UNK_TOKEN] + [\n",
        "    word for word, _ in word_counts.most_common(VOCAB_LIMIT - 1)\n",
        "]\n",
        "\n",
        "word2index = {word: idx for idx, word in enumerate(vocab)}\n",
        "index2word = {idx: word for word, idx in word2index.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "UNK_INDEX = word2index[UNK_TOKEN]\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"UNK index:\", word2index[UNK_TOKEN])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX8p6TH9ziux"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for sentence in sentences:\n",
        "    indexed_sentence = [\n",
        "        # each word is replaced by its index from word2index\n",
        "        # this is to make dataset ready for model training\n",
        "        word2index.get(word, word2index[UNK_TOKEN])\n",
        "        for word in sentence\n",
        "    ]\n",
        "    corpus.append(indexed_sentence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDluMOkCzP6H"
      },
      "source": [
        "## 2. Build Co-occurence Matrix X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-O1P2CJzP6H"
      },
      "source": [
        "Here, we need to count the co-occurence of two words given some window size.  We gonna use window size of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4cuH4S0z0fg"
      },
      "outputs": [],
      "source": [
        "def generate_skipgrams(corpus, window_size=2):\n",
        "    skip_grams = []\n",
        "\n",
        "    for doc in corpus:\n",
        "        for i, center_word in enumerate(doc):\n",
        "            for j in range(\n",
        "                max(0, i - window_size),\n",
        "                min(len(doc), i + window_size + 1)\n",
        "            ):\n",
        "                if i != j:\n",
        "                    skip_grams.append((center_word, doc[j]))\n",
        "\n",
        "    return skip_grams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcz6JJhJz37p",
        "outputId": "7d8e57c5-4033-4080-b6cc-f045380b942e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total skip-grams: 3421336\n"
          ]
        }
      ],
      "source": [
        "# DEFAULT window size = 2 \n",
        "WINDOW_SIZE = 2\n",
        "skip_grams = generate_skipgrams(sentences, window_size=WINDOW_SIZE)\n",
        "\n",
        "print(\"Total skip-grams:\", len(skip_grams))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbQv7BJ9z9Ci",
        "outputId": "587d5fcf-8252-4165-bb98-50d5ce037e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total co-occurrence pairs: 1401533\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "X_ik = defaultdict(int)\n",
        "\n",
        "for pair in skip_grams:\n",
        "    X_ik[pair] += 1\n",
        "\n",
        "print(\"Total co-occurrence pairs:\", len(X_ik))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAujclUOzP6I"
      },
      "source": [
        "**Weighting function**\n",
        "\n",
        "GloVe includes a weighting function to scale down too frequent words.\n",
        "\n",
        "<img src = \"../figures/glove_weighting_func.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPzgQ1_O0Bqz"
      },
      "outputs": [],
      "source": [
        "x_max = 100\n",
        "alpha = 0.75\n",
        "\n",
        "weighting_dic = {}\n",
        "\n",
        "for pair, count in X_ik.items():\n",
        "    if count < x_max:\n",
        "        weighting_dic[pair] = (count / x_max) ** alpha\n",
        "    else:\n",
        "        weighting_dic[pair] = 1.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuvn7pB8zP6J"
      },
      "source": [
        "**Prepare train data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M96LFCbL0KL2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "\n",
        "    random_inputs, random_labels, random_coocs, random_weightings = [], [], [], []\n",
        "\n",
        "    skip_grams_id = [\n",
        "        (word2index.get(w1, UNK_INDEX),  word2index.get(w2, UNK_INDEX)) for w1, w2 in skip_grams\n",
        "    ]\n",
        "\n",
        "    random_index = np.random.choice(\n",
        "        range(len(skip_grams_id)),\n",
        "        batch_size,\n",
        "        replace=False\n",
        "    )\n",
        "\n",
        "    for index in random_index:\n",
        "        random_inputs.append([skip_grams_id[index][0]])\n",
        "        random_labels.append([skip_grams_id[index][1]])\n",
        "\n",
        "        pair = skip_grams[index]\n",
        "        cooc = X_ik[pair]\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "\n",
        "    return (\n",
        "        np.array(random_inputs),\n",
        "        np.array(random_labels),\n",
        "        np.array(random_coocs),\n",
        "        np.array(random_weightings)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY_sjUolzP6L"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgirCPQ40OPC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Glove(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.center_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.context_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.center_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.context_bias = nn.Embedding(vocab_size, 1)\n",
        "\n",
        "    def forward(self, center, context, cooc, weighting):\n",
        "        center_embed = self.center_embedding(center).squeeze(1)\n",
        "        context_embed = self.context_embedding(context).squeeze(1)\n",
        "\n",
        "        center_bias = self.center_bias(center).squeeze(1)\n",
        "        context_bias = self.context_bias(context).squeeze(1)\n",
        "\n",
        "        inner_product = torch.sum(center_embed * context_embed, dim=1, keepdim=True)\n",
        "\n",
        "        loss = weighting * (\n",
        "            inner_product + center_bias + context_bias - cooc\n",
        "        ) ** 2\n",
        "\n",
        "        return torch.mean(loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvOjixY_zP6M"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE-Wwoni0Xhb"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "batch_size = 128\n",
        "num_epochs = 5000\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Glove(vocab_size, embedding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7me6cGb0kG7",
        "outputId": "e5bc8414-c00a-4702-ddb9-c120723ff5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 500 | Loss: 20.272104\n",
            "Epoch 1000 | Loss: 18.815372\n",
            "Epoch 1500 | Loss: 11.936865\n",
            "Epoch 2000 | Loss: 9.624596\n",
            "Epoch 2500 | Loss: 8.206407\n",
            "Epoch 3000 | Loss: 5.208466\n",
            "Epoch 3500 | Loss: 5.306939\n",
            "Epoch 4000 | Loss: 6.229774\n",
            "Epoch 4500 | Loss: 5.293838\n",
            "Epoch 5000 | Loss: 8.381731\n",
            "Training completed in 6627.40 seconds\n",
            "Final loss: 8.381731033325195\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    x, y, cooc, weighting = random_batch(\n",
        "        batch_size,\n",
        "        sentences,\n",
        "        skip_grams,\n",
        "        X_ik,\n",
        "        weighting_dic\n",
        "    )\n",
        "\n",
        "    x_tensor = torch.LongTensor(x)\n",
        "    y_tensor = torch.LongTensor(y)\n",
        "    cooc_tensor = torch.FloatTensor(cooc)\n",
        "    weighting_tensor = torch.FloatTensor(weighting)\n",
        "\n",
        "    loss = model(x_tensor, y_tensor, cooc_tensor, weighting_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item());\n",
        "\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(f\"Epoch {epoch+1} | Loss: {loss.item():.6f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "print(\"Final loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jAJD7bv0nkM",
        "outputId": "46823942-fe61-4a5a-c8b4-4bcdb6f6fc0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: torch.Size([10000, 100])\n"
          ]
        }
      ],
      "source": [
        "embeddings = model.center_embedding.weight.data\n",
        "print(\"Embedding matrix shape:\", embeddings.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQBrM8I0-f30"
      },
      "source": [
        "**Save the trained GloVe model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcfrrs8N-39x",
        "outputId": "f58c7479-d441-46ff-cd6f-7b4abfb41b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to Glove.pth\n"
          ]
        }
      ],
      "source": [
        "MODEL_PATH = \"Glove.pth\"\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"word2index\": word2index,\n",
        "    \"index2word\": index2word,\n",
        "    \"embedding_dim\": embedding_dim\n",
        "}, MODEL_PATH)\n",
        "\n",
        "print(\"Model saved to\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbJyGWjk-7m_"
      },
      "source": [
        "**Load the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6CZ9ZsR_EZ7",
        "outputId": "4103457c-def6-4e6c-cfbc-6116c7be8a35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Glove(\n",
              "  (center_embedding): Embedding(10000, 100)\n",
              "  (context_embedding): Embedding(10000, 100)\n",
              "  (center_bias): Embedding(10000, 1)\n",
              "  (context_bias): Embedding(10000, 1)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load(\"Glove.pth\", map_location=\"cpu\")\n",
        "\n",
        "word2index = checkpoint[\"word2index\"]\n",
        "index2word = checkpoint[\"index2word\"]\n",
        "embedding_dim = checkpoint[\"embedding_dim\"]\n",
        "\n",
        "vocab_size = len(word2index)\n",
        "\n",
        "model = Glove(vocab_size, embedding_dim)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WfZCRi8_Hwe"
      },
      "source": [
        "**Extract embeddings from the loaded model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmk52Sl2_NNF"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "embeddings = model.center_embedding.weight.data\n",
        "embeddings = F.normalize(embeddings, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxFT7miO_eGr"
      },
      "source": [
        "**Evaluate semantic & syntactic accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-2r-BS5_0iK"
      },
      "outputs": [],
      "source": [
        "def load_analogy_dataset(filepath):\n",
        "    semantic = []\n",
        "    syntactic = []\n",
        "\n",
        "    current_section = None\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line.startswith(\":\"):\n",
        "                if \"capital-common-countries\" in line:\n",
        "                    current_section = \"semantic\"\n",
        "                elif \"past-tense\" in line:\n",
        "                    current_section = \"syntactic\"\n",
        "                else:\n",
        "                    current_section = None\n",
        "                continue\n",
        "\n",
        "            if current_section is None:\n",
        "                continue\n",
        "\n",
        "            words = line.lower().split()\n",
        "            if len(words) != 4:\n",
        "                continue\n",
        "\n",
        "            if current_section == \"semantic\":\n",
        "                semantic.append(words)\n",
        "            else:\n",
        "                syntactic.append(words)\n",
        "\n",
        "    return semantic, syntactic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaKfN06c_61I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def analogy_accuracy(analogies, embeddings, word2index, index2word):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    vocab_size = embeddings.size(0)\n",
        "\n",
        "    for a, b, c, d in analogies:\n",
        "        if a not in word2index or b not in word2index \\\n",
        "           or c not in word2index or d not in word2index:\n",
        "            continue\n",
        "\n",
        "        va = embeddings[word2index[a]]\n",
        "        vb = embeddings[word2index[b]]\n",
        "        vc = embeddings[word2index[c]]\n",
        "\n",
        "        # Word2Vec analogy: b - a + c\n",
        "        target_vec = vb - va + vc\n",
        "        target_vec = F.normalize(target_vec.unsqueeze(0), dim=1)\n",
        "\n",
        "        # Cosine similarity with all words\n",
        "        similarities = torch.matmul(target_vec, embeddings.T).squeeze()\n",
        "\n",
        "        # Exclude query words\n",
        "        similarities[word2index[a]] = -1e9\n",
        "        similarities[word2index[b]] = -1e9\n",
        "        similarities[word2index[c]] = -1e9\n",
        "\n",
        "        predicted_index = torch.argmax(similarities).item()\n",
        "        predicted_word = index2word[predicted_index]\n",
        "\n",
        "        if predicted_word == d:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return correct / total if total > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjFYM5B4_kzS",
        "outputId": "d206469c-3486-4927-ff3c-a0134027e9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic accuracy: 0.0000\n",
            "Syntactic accuracy: 0.0000\n"
          ]
        }
      ],
      "source": [
        "semantic, syntactic = load_analogy_dataset(\"/content/sample_data/word_analogies_dataset.txt\")\n",
        "\n",
        "semantic_acc = analogy_accuracy(\n",
        "    semantic, embeddings, word2index, index2word\n",
        ")\n",
        "\n",
        "syntactic_acc = analogy_accuracy(\n",
        "    syntactic, embeddings, word2index, index2word\n",
        ")\n",
        "\n",
        "print(f\"Semantic accuracy: {semantic_acc:.4f}\")\n",
        "print(f\"Syntactic accuracy: {syntactic_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzn1Z6SGuZt2"
      },
      "source": [
        "**Load similarity dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qRgwLW1uugR0",
        "outputId": "0f3db902-d255-40d0-e86d-545d0c8ea35c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sim_df\",\n  \"rows\": 353,\n  \"fields\": [\n    {\n      \"column\": \"Word 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 206,\n        \"samples\": [\n          \"benchmark\",\n          \"atmosphere\",\n          \"weapon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"animal\",\n          \"quarrel\",\n          \"payment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Human (Mean)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0329921866962284,\n        \"min\": 0.3125,\n        \"max\": 10.0,\n        \"num_unique_values\": 146,\n        \"samples\": [\n          2.75,\n          3.1875,\n          4.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sim_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3416ac07-87e5-4ff6-8922-62f36ae07bdb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Human (Mean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admission</td>\n",
              "      <td>ticket</td>\n",
              "      <td>5.5360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>chemistry</td>\n",
              "      <td>4.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>metal</td>\n",
              "      <td>6.6250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>announcement</td>\n",
              "      <td>effort</td>\n",
              "      <td>2.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>announcement</td>\n",
              "      <td>news</td>\n",
              "      <td>7.1875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3416ac07-87e5-4ff6-8922-62f36ae07bdb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3416ac07-87e5-4ff6-8922-62f36ae07bdb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3416ac07-87e5-4ff6-8922-62f36ae07bdb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Word 1     Word 2  Human (Mean)\n",
              "0     admission     ticket        5.5360\n",
              "1       alcohol  chemistry        4.1250\n",
              "2      aluminum      metal        6.6250\n",
              "3  announcement     effort        2.0625\n",
              "4  announcement       news        7.1875"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load similarity dataset\n",
        "sim_df = pd.read_csv(\"/content/sample_data/wordsim353crowd.csv\")\n",
        "\n",
        "sim_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e2DSab5uj0G"
      },
      "source": [
        "**Compute dot-product similarities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W87oYxLfupBE",
        "outputId": "6735f931-996b-4e15-f409-d132fe919ce9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-573930044.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  w1 = str(row[0]).lower()\n",
            "/tmp/ipython-input-573930044.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  w2 = str(row[1]).lower()\n",
            "/tmp/ipython-input-573930044.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  human_score = float(row[2])\n"
          ]
        }
      ],
      "source": [
        "model_sims = []\n",
        "human_sims = []\n",
        "\n",
        "UNK_INDEX = word2index.get(\"<UNK>\")\n",
        "\n",
        "for _, row in sim_df.iterrows():\n",
        "    w1 = str(row[0]).lower()\n",
        "    w2 = str(row[1]).lower()\n",
        "    human_score = float(row[2])\n",
        "\n",
        "    idx1 = word2index.get(w1, UNK_INDEX)\n",
        "    idx2 = word2index.get(w2, UNK_INDEX)\n",
        "\n",
        "    v1 = embeddings[idx1]\n",
        "    v2 = embeddings[idx2]\n",
        "\n",
        "    dot_sim = torch.dot(v1, v2).item()\n",
        "\n",
        "    model_sims.append(dot_sim)\n",
        "    human_sims.append(human_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8g8AzNgus1j"
      },
      "source": [
        "**Spearman correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmo6Cki5ux7W",
        "outputId": "43c51f5e-e659-4a38-ae64-9394f625db95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman Correlation: 0.0993\n",
            "P-value: 6.2390e-02\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "correlation, p_value = spearmanr(model_sims, human_sims)\n",
        "\n",
        "print(f\"Spearman Correlation: {correlation:.4f}\")\n",
        "print(f\"P-value: {p_value:.4e}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
