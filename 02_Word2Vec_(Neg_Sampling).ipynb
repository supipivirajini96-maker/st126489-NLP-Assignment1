{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPC3BIG4Q7kY"
      },
      "source": [
        "# Word2Vec (Negative Sampling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IercZW2DQ7kb",
        "outputId": "94505dff-a6ed-4155-8a39-037a5561b311"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to\n",
            "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1abff2b6d30>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import reuters, stopwords\n",
        "\n",
        "nltk.download('reuters')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# to ensure to produce same random number to debug and model comparison\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dpzgYIvQ7kd"
      },
      "source": [
        "**Prepare the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qECAem_VRVAw",
        "outputId": "3561bca9-4af2-40ba-9db3-2cff76a78955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 10788\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "sentences = []\n",
        "\n",
        "for fileid in reuters.fileids():\n",
        "    words = [\n",
        "        w.lower()\n",
        "        for w in reuters.words(fileid)\n",
        "        # clean the dataset document by removing stopwords\n",
        "        if w.isalpha() and w.lower() not in stop_words\n",
        "    ]\n",
        "    sentences.append(words)\n",
        "\n",
        "print(\"Total sentences:\", len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVpNjEo4RXIf",
        "outputId": "b70b60b0-5bad-4619-a9da-ddfb935100c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 10000\n",
            "UNK index: 0\n"
          ]
        }
      ],
      "source": [
        "# set vocab limit to avoid training the model fneeds GPU for londer period\n",
        "VOCAB_LIMIT = 10000\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "all_words = [w for sentence in sentences for w in sentence]\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# build the vocabulary\n",
        "vocab = [UNK_TOKEN] + [\n",
        "    word for word, _ in word_counts.most_common(VOCAB_LIMIT - 1)\n",
        "]\n",
        "\n",
        "word2index = {word: idx for idx, word in enumerate(vocab)}\n",
        "index2word = {idx: word for word, idx in word2index.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"UNK index:\", word2index[UNK_TOKEN])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "14I4-tBiReZx"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for sentence in sentences:\n",
        "    indexed_sentence = [\n",
        "        # each word is replaced by its index from word2index\n",
        "        # this is to make dataset ready for model training\n",
        "        word2index.get(word, word2index[UNK_TOKEN])\n",
        "        for word in sentence\n",
        "    ]\n",
        "    corpus.append(indexed_sentence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_okcfniQ7kf"
      },
      "source": [
        "**Prepare train Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OS5nO0L_Q7kf"
      },
      "outputs": [],
      "source": [
        "# dynamic windows where default is 2\n",
        "def random_batch(batch_size, corpus, window_size=2):\n",
        "    input_batch = []\n",
        "    label_batch = []\n",
        "\n",
        "    while len(input_batch) < batch_size:\n",
        "\n",
        "        # pick a random sentence index\n",
        "        sentence_idx = random.randint(0, len(corpus) - 1)\n",
        "        sentence = corpus[sentence_idx]\n",
        "\n",
        "        # ensure sentence is long enough to pick a center and context word\n",
        "        if len(sentence) < 2 * window_size + 1:\n",
        "            continue\n",
        "\n",
        "        # pick a random center word position within the sentence\n",
        "        center_word_pos = random.randint(window_size, len(sentence) - 1 - window_size)\n",
        "        center_word_index = sentence[center_word_pos]\n",
        "\n",
        "        # pick a random context word position within the window around the center word\n",
        "        # and ensure it's not the center word itself\n",
        "        context_word_pos = random.choice(\n",
        "            list(range(center_word_pos - window_size, center_word_pos + window_size + 1))\n",
        "        )\n",
        "        if context_word_pos == center_word_pos:\n",
        "            continue\n",
        "        context_word_index = sentence[context_word_pos]\n",
        "\n",
        "        input_batch.append(center_word_index)\n",
        "        label_batch.append(context_word_index)\n",
        "\n",
        "    return input_batch, label_batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Unigram Table**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIrQHIgKQ7ki"
      },
      "source": [
        "$$P(w)=U(w)^{3/4}/Z$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQWfbuTLQ7kj",
        "outputId": "07fe53b4-4023-4bc9-9a7a-ad4def2b9ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram table size: 25225\n"
          ]
        }
      ],
      "source": [
        "num_total_words = sum(word_counts.values())\n",
        "\n",
        "z = sum([count ** 0.75 for count in word_counts.values()])\n",
        "\n",
        "unigram_table = []\n",
        "\n",
        "for v in vocab:\n",
        "    if v == \"<UNK>\":\n",
        "        continue\n",
        "    uw = word_counts[v] / num_total_words\n",
        "    uw_alpha = int((uw ** 0.75) / z * 1e9)  # Increased scale factor\n",
        "    unigram_table.extend([v] * uw_alpha)\n",
        "\n",
        "print(\"Unigram table size:\", len(unigram_table))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqXGC-5SQ7kj"
      },
      "source": [
        "\n",
        "\n",
        "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7peY4-6Q7kj"
      },
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, word2index):\n",
        "    return torch.LongTensor([word2index[w] for w in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2lRvvTJQ7kj"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.shape[0]\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):  #(1, k)\n",
        "        target_index = targets[i].item()\n",
        "        nsample      = []\n",
        "        while (len(nsample) < k):\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))\n",
        "\n",
        "    return torch.cat(neg_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abloFLUnQ7kj"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "x, y = random_batch(batch_size, corpus)\n",
        "x_tensor = torch.LongTensor(x)\n",
        "y_tensor = torch.LongTensor(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5bUpj60Q7kj"
      },
      "outputs": [],
      "source": [
        "k = 5\n",
        "neg_samples = negative_sampling(y_tensor, unigram_table, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuRHGKGxQ7kj",
        "outputId": "d8c8c926-22b1-4522-f30e-ee6207d310d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_tensor[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytj8Gd9eQ7kk",
        "outputId": "955c2556-cee9-432c-e2f7-31b67dd4245c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 438, 2393, 1114,  590, 3016])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg_samples[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvZqPkHLQ7kk"
      },
      "source": [
        "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e-7bw1IQ7kk"
      },
      "outputs": [],
      "source": [
        "class SkipgramNeg(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.embedding_center = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding_outside = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, center, outside, negative):\n",
        "        center_emb = self.embedding_center(center).squeeze(1)\n",
        "        outside_emb = self.embedding_outside(outside).squeeze(1)\n",
        "        neg_emb = self.embedding_outside(negative)\n",
        "\n",
        "        pos_score = torch.sum(center_emb * outside_emb, dim=1)\n",
        "        pos_loss = torch.log(torch.sigmoid(pos_score))\n",
        "\n",
        "        neg_score = torch.bmm(\n",
        "            neg_emb, center_emb.unsqueeze(2)\n",
        "        ).squeeze(2)\n",
        "        neg_loss = torch.sum(torch.log(torch.sigmoid(-neg_score)), dim=1)\n",
        "\n",
        "        return -torch.mean(pos_loss + neg_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9zRwHYpQ7kl"
      },
      "outputs": [],
      "source": [
        "#test your model\n",
        "embedding_dim = 100\n",
        "batch_size = 128\n",
        "num_epochs = 5000\n",
        "learning_rate = 0.001\n",
        "k = 5\n",
        "WINDOW_SIZE = 2  # default (dynamic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tXJTmInUnWw"
      },
      "outputs": [],
      "source": [
        "model = SkipgramNeg(vocab_size, embedding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVw7Ny8wQ7kl",
        "outputId": "aedda290-8b63-4199-9caf-24f13b449311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial test loss (before training): 21.834829330444336\n"
          ]
        }
      ],
      "source": [
        "x_batch, y_batch = random_batch(batch_size, corpus, window_size=WINDOW_SIZE)\n",
        "\n",
        "input_tensor = torch.LongTensor(x_batch)\n",
        "label_tensor = torch.LongTensor(y_batch)\n",
        "\n",
        "neg_samples = negative_sampling(label_tensor, unigram_table, k)\n",
        "test_loss = model(input_tensor, label_tensor, neg_samples)\n",
        "\n",
        "print(\"Initial test loss (before training):\", test_loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8fUwLRLQ7km"
      },
      "source": [
        "**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOTqeXlKQ7kn",
        "outputId": "18ad8d8f-268b-4342-9d25-f795cf14fe44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    500 | Loss: 22.048492\n",
            "Epoch   1000 | Loss: 18.929867\n",
            "Epoch   1500 | Loss: 20.520149\n",
            "Epoch   2000 | Loss: 16.697109\n",
            "Epoch   2500 | Loss: 16.945498\n",
            "Epoch   3000 | Loss: 15.586607\n",
            "Epoch   3500 | Loss: 13.788391\n",
            "Epoch   4000 | Loss: 14.125816\n",
            "Epoch   4500 | Loss: 11.145334\n",
            "Epoch   5000 | Loss: 12.844395\n",
            "\n",
            "Training completed in 113.68 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "    input_tensor = torch.LongTensor(input_batch)\n",
        "    label_tensor = torch.LongTensor(label_batch)\n",
        "\n",
        "    #predict\n",
        "    neg_samples = negative_sampling(label_tensor, unigram_table, k)\n",
        "    loss = model(input_tensor, label_tensor, neg_samples)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer.step()\n",
        "\n",
        "    #print the loss\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(f\"Epoch {epoch+1:6.0f} | Loss: {loss:2.6f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\nTraining completed in {end_time - start_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqNt3PXO7_Vv"
      },
      "source": [
        "**Save the trained Word2Vec model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TcNprFs8BrK",
        "outputId": "62f5d84a-2dc5-45a8-cf5a-cfe46c760c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to word2vec_neg_sampling.pth\n"
          ]
        }
      ],
      "source": [
        "MODEL_PATH = \"word2vec_neg_sampling.pth\"\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"word2index\": word2index,\n",
        "    \"index2word\": index2word,\n",
        "    \"embedding_dim\": embedding_dim\n",
        "}, MODEL_PATH)\n",
        "\n",
        "print(\"Model saved to\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUVJBOS8J3P"
      },
      "source": [
        "**Load the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HojtYu18GWl",
        "outputId": "c8528eb2-3a1d-4868-f101-8b4f1e2720f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SkipgramNeg(\n",
              "  (embedding_center): Embedding(10000, 100)\n",
              "  (embedding_outside): Embedding(10000, 100)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load(\"word2vec_neg_sampling.pth\", map_location=\"cpu\")\n",
        "\n",
        "word2index = checkpoint[\"word2index\"]\n",
        "index2word = checkpoint[\"index2word\"]\n",
        "embedding_dim = checkpoint[\"embedding_dim\"]\n",
        "\n",
        "vocab_size = len(word2index)\n",
        "\n",
        "model = SkipgramNeg(vocab_size, embedding_dim)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhqnCecJ8kev"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "embeddings = model.embedding_center.weight.data\n",
        "embeddings = F.normalize(embeddings, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHafh3-_8WIU"
      },
      "source": [
        "**Evaluate semantic & syntactic accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8YKL2JJ8p2V"
      },
      "outputs": [],
      "source": [
        "# load word analogies dataset and returns two lists for semantic and synthetic evaluation\n",
        "def load_analogy_dataset(filepath):\n",
        "    semantic = []\n",
        "    syntactic = []\n",
        "\n",
        "    current_section = None\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line.startswith(\":\"):\n",
        "                if \"capital-common-countries\" in line:\n",
        "                    current_section = \"semantic\"\n",
        "                elif \"past-tense\" in line:\n",
        "                    current_section = \"syntactic\"\n",
        "                else:\n",
        "                    current_section = None\n",
        "                continue\n",
        "\n",
        "            if current_section is None:\n",
        "                continue\n",
        "\n",
        "            words = line.lower().split()\n",
        "            if len(words) != 4:\n",
        "                continue\n",
        "\n",
        "            if current_section == \"semantic\":\n",
        "                semantic.append(words)\n",
        "            else:\n",
        "                syntactic.append(words)\n",
        "\n",
        "    return semantic, syntactic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVnd-2Dx8p6t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def analogy_accuracy(analogies, embeddings, word2index, index2word):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    vocab_size = embeddings.size(0)\n",
        "\n",
        "    for a, b, c, d in analogies:\n",
        "        if a not in word2index or b not in word2index \\\n",
        "           or c not in word2index or d not in word2index:\n",
        "            continue\n",
        "\n",
        "        va = embeddings[word2index[a]]\n",
        "        vb = embeddings[word2index[b]]\n",
        "        vc = embeddings[word2index[c]]\n",
        "\n",
        "        # Word2Vec analogy: b - a + c\n",
        "        target_vec = vb - va + vc\n",
        "        target_vec = F.normalize(target_vec.unsqueeze(0), dim=1)\n",
        "\n",
        "        # Cosine similarity with all words\n",
        "        similarities = torch.matmul(target_vec, embeddings.T).squeeze()\n",
        "\n",
        "        # Exclude query words\n",
        "        similarities[word2index[a]] = -1e9\n",
        "        similarities[word2index[b]] = -1e9\n",
        "        similarities[word2index[c]] = -1e9\n",
        "\n",
        "        predicted_index = torch.argmax(similarities).item()\n",
        "        predicted_word = index2word[predicted_index]\n",
        "\n",
        "        if predicted_word == d:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return correct / total if total > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3JjzM5g8amL",
        "outputId": "de74588d-4766-4245-fbe5-5d4f9c4e9348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic accuracy: 0.0000\n",
            "Syntactic accuracy: 0.0000\n"
          ]
        }
      ],
      "source": [
        "semantic, syntactic = load_analogy_dataset(\"/content/sample_data/word_analogies_dataset.txt\")\n",
        "\n",
        "semantic_acc = analogy_accuracy(\n",
        "    semantic, embeddings, word2index, index2word\n",
        ")\n",
        "\n",
        "syntactic_acc = analogy_accuracy(\n",
        "    syntactic, embeddings, word2index, index2word\n",
        ")\n",
        "\n",
        "print(f\"Semantic accuracy: {semantic_acc:.4f}\")\n",
        "print(f\"Syntactic accuracy: {syntactic_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExCz80Bvq9ZC"
      },
      "source": [
        "**Load similarity dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YbRo4K-BrCkp",
        "outputId": "79df8886-21fb-44e7-f061-74e04e4d8530"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sim_df\",\n  \"rows\": 353,\n  \"fields\": [\n    {\n      \"column\": \"Word 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 206,\n        \"samples\": [\n          \"benchmark\",\n          \"atmosphere\",\n          \"weapon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"animal\",\n          \"quarrel\",\n          \"payment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Human (Mean)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0329921866962284,\n        \"min\": 0.3125,\n        \"max\": 10.0,\n        \"num_unique_values\": 146,\n        \"samples\": [\n          2.75,\n          3.1875,\n          4.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sim_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7408af74-7766-47b4-b2ce-8a7ccf4d19e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Human (Mean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admission</td>\n",
              "      <td>ticket</td>\n",
              "      <td>5.5360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>chemistry</td>\n",
              "      <td>4.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>metal</td>\n",
              "      <td>6.6250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>announcement</td>\n",
              "      <td>effort</td>\n",
              "      <td>2.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>announcement</td>\n",
              "      <td>news</td>\n",
              "      <td>7.1875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7408af74-7766-47b4-b2ce-8a7ccf4d19e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7408af74-7766-47b4-b2ce-8a7ccf4d19e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7408af74-7766-47b4-b2ce-8a7ccf4d19e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Word 1     Word 2  Human (Mean)\n",
              "0     admission     ticket        5.5360\n",
              "1       alcohol  chemistry        4.1250\n",
              "2      aluminum      metal        6.6250\n",
              "3  announcement     effort        2.0625\n",
              "4  announcement       news        7.1875"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load similarity dataset\n",
        "sim_df = pd.read_csv(\"/content/sample_data/wordsim353crowd.csv\")\n",
        "\n",
        "sim_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlcHNJVIrikF"
      },
      "source": [
        "**Compute dot-product similarities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQVh13TurrTG",
        "outputId": "c38162ae-3649-437d-ebdd-78e4f3c80c72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-573930044.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  w1 = str(row[0]).lower()\n",
            "/tmp/ipython-input-573930044.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  w2 = str(row[1]).lower()\n",
            "/tmp/ipython-input-573930044.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  human_score = float(row[2])\n"
          ]
        }
      ],
      "source": [
        "model_sims = []\n",
        "human_sims = []\n",
        "\n",
        "UNK_INDEX = word2index.get(\"<UNK>\")\n",
        "\n",
        "for _, row in sim_df.iterrows():\n",
        "    w1 = str(row[0]).lower()\n",
        "    w2 = str(row[1]).lower()\n",
        "    human_score = float(row[2])\n",
        "\n",
        "    idx1 = word2index.get(w1, UNK_INDEX)\n",
        "    idx2 = word2index.get(w2, UNK_INDEX)\n",
        "\n",
        "    v1 = embeddings[idx1]\n",
        "    v2 = embeddings[idx2]\n",
        "\n",
        "    dot_sim = torch.dot(v1, v2).item()\n",
        "\n",
        "    model_sims.append(dot_sim)\n",
        "    human_sims.append(human_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxKPd1pnrvUO"
      },
      "source": [
        "**Spearman correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSzNyq72r0hC",
        "outputId": "d1b45252-8c73-4bd2-e7f9-bda73b6554f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman Correlation: 0.1065\n",
            "P-value: 4.5555e-02\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "correlation, p_value = spearmanr(model_sims, human_sims)\n",
        "\n",
        "print(f\"Spearman Correlation: {correlation:.4f}\")\n",
        "print(f\"P-value: {p_value:.4e}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
